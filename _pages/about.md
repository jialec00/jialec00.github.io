---
layout: about
title: About
permalink: /
# subtitle:

profile:
  align: right
  image: avatar.jpg
  image_circular: false # crops the image to make it circular
  more_info: <sup>Email:<!--> jialec [at] stanford [dot] edu<sup>

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---
<!-- 
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->


I am a fourth-year Ph.D. student at Stanford University, advised by <a href="https://www.aaronsidford.com/">Prof. Aaron Sidford</a>. My theory research focuses on the design and analysis of graph algorithms.

In the past two years, I mainly worked on the fully dynamic $$(1-\varepsilon)$$-approximate matching problem, with particular attention to the gaps between unweighted and weighted matchings, and between bipartite and non-bipartite settings. Our work **[BCDLST25]** and **[BC26]** makes significant progress toward closing these gaps by developing a meta-algorithm that converts any $$(1-\mathrm{poly}(\varepsilon))$$-approximate algorithm for unweighted bipartite graphs into a $$(1-\varepsilon)$$-approximate algorithm for weighted general graphs, with only $$\mathrm{poly}(\log n/\varepsilon)$$ overhead.

Recently, I have been deeply excited by the rapid progress in AI, particularly its reasoning capabilities in mathematics and coding. While I am still catching up with the field, I am especially interested in its potential to carry out independent research and tackle complex decision-making, its societal influence—including how it may reshape the beliefs of experts within their own domains—and its fundamental challenge of aligning these systems more robustly with human values.

<!-- the following questions:
* How can human domain knowledge further enhance models’ reasoning abilities toward independent research?
* To what extent can models influence or manipulate the beliefs of experts within their own fields?
* Do models exhibit a stable utility function when operating in complex decision-making environments?
* How can we align models more fundamentally and robustly with human values? -->

<!-- Previously, I obtained my B.Sc., Summa Cum Laude in Computer Science and Technology from Turing Class, Peking University, advised by <a href="https://cfcs.pku.edu.cn/yuqkong/">Prof. Yuqing Kong</a>. During my undergraduate years, I am fortunate to have worked closely with <a href="https://procaccia.info/">Prof. Ariel Procaccia</a> on Fair Division and with <a href="https://sites.northwestern.edu/hartline/">Prof. Jason Hartline</a> on Algorithmic Fairness. -->
